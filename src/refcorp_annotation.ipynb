{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation der Volksverhetzung im Referenzdatensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausschnittdatensätze (Train, Test) erstellen, in dem nur die Einträge mit dem feinen Label \"HATE\" vorkommen\n",
    "# Bereits erstellt, nicht nochmals ausführen\n",
    "# zweimal ausgeführt (korrigierte Formatierungen und IDs) --> Shuffle hat die Reihenfolge der Ausgangsdatei verändert\n",
    "# (allerdings irrelevant, da alle Tweets IDs haben)\n",
    "\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\RefKorpHateSpeechDe_Test.txt\", mode=\"r\", encoding=\"utf-8\") as hatetrainin:\n",
    "#    all_cont = hatetrainin.readlines()\n",
    "#    all_cont = all_cont[1:]\n",
    "#    sep_cont = [entry.strip().split(\"\\t\") for entry in all_cont]\n",
    "#    hate = []\n",
    "#    for tweet in sep_cont:\n",
    "#        if tweet[3] == \"HATE\": hate.append(tweet)\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\RefKorpHateSpeechDe_Test_HATE.txt\", mode=\"w\", encoding=\"utf-8\") as hatetrainout:\n",
    "#    for line in hate:\n",
    "#        hatetrainout.write(\"\\t\".join(line)+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test - HATE Dateien des Referenzdatensatzes als JSON-Dateien speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\RefKorpHateSpeechDe_Test_HATE.txt\", mode=\"r\", encoding=\"utf-8\") as intxt:\n",
    "#    tws = intxt.readlines()\n",
    "#    conts = [elem.strip(\"\\n\").split(\"\\t\") for elem in tws]\n",
    "#    cont_dicts = [{\"id\":elem[0], \"text\":elem[1], \"tag1\":elem[2], \"tag2\":elem[3]} for elem in conts]\n",
    "\n",
    "#import json\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\RefKorpHateSpeechDe_Test_HATE.json\", mode=\"w\", encoding=\"utf-8\") as jsonout:\n",
    "#    prep_cont = json.dumps(cont_dicts)\n",
    "#    jsonout.write(prep_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotation: Logikprüfung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_anno(datensatz):\n",
    "    \"\"\"Annotationslogik checken und Problemfälle sammeln\"\"\"\n",
    "    probleme = []\n",
    "    for entry in datensatz:\n",
    "        if not anno_logik_check(entry[\"label\"]): probleme.append(entry)\n",
    "    return probleme\n",
    "\n",
    "\n",
    "def anno_logik_check(labelset):\n",
    "    \"\"\" Die Annotationslogik checken:\n",
    "        Input: Labelmenge als Liste\n",
    "        Output: True (falls alles korrekt) / False (falls irgendein Problem vorliegt)    \n",
    "    \"\"\"\n",
    "    labelset = set(labelset)\n",
    "    korrekt = True\n",
    "    if len(labelset) == 0:\n",
    "        korrekt = False\n",
    "    elif (len(labelset) == 1) and (\"KEINE\" not in labelset):\n",
    "        korrekt = False\n",
    "    else:\n",
    "        # 1. VVH-ALLG interne Logik\n",
    "        if \"VVH-ALLG\" in labelset:\n",
    "            # Mind. eine Art der Tathandlung ggb.\n",
    "            if {\"Aufstachelung zu Hass\", \"Aufforderung zu Gewalt- oder Willkürmaßnahmen\", \"Angriff der Menschenwürde\"} & labelset == set():\n",
    "                korrekt = False\n",
    "            # Mind. eine Gruppe genannt\n",
    "            if {\"Nationalität\", 'ethnische Herkunft / \"Rasse\"', \"Religion / Weltanschauung\",\n",
    "                    \"Politische Einstellung\", \"Geschlecht\", \"Anderes Merkmal\"} & labelset == set():\n",
    "                korrekt = False\n",
    "            # keine VVH-NS Labels\n",
    "            if {\"VVH-NS\", \"Billigen\", \"Verherrlichen\", \"Verharmlosen\", \"Leugnen\", \"Rechtfertigen\"} & labelset != set():\n",
    "                korrekt = False\n",
    "            if \"KEINE\" in labelset: korrekt = False\n",
    "\n",
    "        # 2. VVH-NS interne Logik\n",
    "        if \"VVH-NS\" in labelset:\n",
    "            # Mind. eine Art der Tathandlung ggb.\n",
    "            if {\"Billigen\", \"Verherrlichen\", \"Verharmlosen\", \"Leugnen\", \"Rechtfertigen\"} & labelset == set(): \n",
    "                korrekt = False\n",
    "            # keine VVH-ALLG Labels\n",
    "            if {\"VVH-ALLG\", \"Aufstachelung zu Hass\", \"Aufforderung zu Gewalt- oder Willkürmaßnahmen\", \"Angriff der Menschenwürde\"} & labelset != set():\n",
    "                korrekt = False \n",
    "            if \"KEINE\" in labelset: korrekt = False\n",
    "        \n",
    "        # 3. Gruppenmerkmale - Logik (in beide Richtungen)\n",
    "\n",
    "        nation = {\"Türkischstämmige Deutsche\", \"Marokkaner:innen\", \"In Deutschland lebende Ausländer:innen\",\n",
    "                    \"Asiat:innen\", \"Pol:innen\", \"Afrikaner:innen\", \"Syrer:innen\", \"Palästinenser:innen\"}\n",
    "        herkunft = {\"POC\", \"Araber:in\"}\n",
    "        religion = {\"Muslim:e/innen\", \"Juden/Jüdinnen\", \"Christ:innen\"}\n",
    "        polit = {\"Die Grünen\", \"die SPD\", \"die Linke\", \"CDU/CSU\", \"AfD\", \"Nazis\", \"Islamist:innen\", \"Kommunist:innen\",\n",
    "                    \"Zionist:innen\", \"NPD\", \"FDP\", \"FridaysForFuture\", \"Pegida\", \"Anarchist:in\"}\n",
    "        geschlecht = {\"Trans/NB-Personen\", \"Frauen\", \"Männer\"}\n",
    "        andere = {\"Flüchtlinge\", \"Asylbewerber:innen\", \"Sich illegal in Deutschland aufhaltende Personen\", \"Migrant:innen\", \"Vorbestrafte\",\n",
    "                    \"Veganer\", \"Senior:innen\", \"Lesben, Schwule, Bi\", \"Kinder\", \"Jugendliche\", \"Polizist:innen\", \"Obdachlose\",\n",
    "                    \"Richter:innen\", \"Analphabet:innen\", \"Soldat:innen\", \"Behinderte\"}\n",
    "\n",
    "        # Richtung 1: falls Gruppe vorhanden, korrektes Merkmal auch vorhanden\n",
    "        for i in nation & labelset:\n",
    "            if \"Nationalität\" not in labelset:\n",
    "                korrekt = False\n",
    "        for j in herkunft & labelset:\n",
    "            if 'ethnische Herkunft / \"Rasse\"' not in labelset:\n",
    "                korrekt = False\n",
    "        for k in religion & labelset:\n",
    "            if \"Religion / Weltanschauung\" not in labelset:\n",
    "                korrekt = False\n",
    "        for l in polit & labelset:\n",
    "            if \"Politische Einstellung\" not in labelset:\n",
    "                korrekt = False\n",
    "        for m in geschlecht & labelset:\n",
    "            if \"Geschlecht\" not in labelset:\n",
    "                korrekt = False\n",
    "        for n in andere & labelset:\n",
    "            if \"Anderes Merkmal\" not in labelset:\n",
    "                korrekt = False\n",
    "\n",
    "        # Richtung 2: falls Merkmal vorhanden, auch eine passende Gruppe vorhanden\n",
    "        if \"Nationalität\" in labelset:\n",
    "            if nation & labelset == set():\n",
    "                korrekt = False\n",
    "        if 'ethnische Herkunft / \"Rasse\"' in labelset:\n",
    "            if herkunft & labelset == set():\n",
    "                korrekt = False\n",
    "        if \"Religion / Weltanschauung\" in labelset:\n",
    "            if religion & labelset == set():\n",
    "                korrekt = False\n",
    "        if \"Politische Einstellung\" in labelset:\n",
    "            if polit & labelset == set():\n",
    "                korrekt = False\n",
    "        if \"Geschlecht\" in labelset:\n",
    "            if geschlecht & labelset == set():\n",
    "                korrekt = False\n",
    "        if \"Anderes Merkmal\" in labelset:\n",
    "            if andere & labelset == set():\n",
    "                korrekt = False\n",
    "\n",
    "    return korrekt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probleme in der Annotationslogik händisch durchgehen\n",
    "\n",
    "import json\n",
    "\n",
    "# Jeweils für die Trainingsdaten und die Testdaten\n",
    "# Beispieleintrag der Annotations-Json-Datei:\n",
    "# {\"id\": \"01112520\", \"data\": \"@SteiblBarbara @Thomas_S_Wagner @RitaKratzert Weitaus schlimmer. Heute ist es nicht mehr Dummheit.  Ein ganzes Volk ist zu (m)wutlosen Zombies dressiert worden.\", \"label\": [\"KEINE\"], \"tag1\": \"NEG\", \"tag2\": \"HATE\"}\n",
    "with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\RefKorpHateSpeechDe_Train_HATE_anno_korrigiert.json\", mode=\"r\", encoding=\"utf-8\") as trainf:\n",
    "    train_anno = trainf.read()\n",
    "    train_annotations = json.loads(train_anno)\n",
    "\n",
    "probleme = check_anno(train_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrekturen für die Trainingsdaten\n",
    " \n",
    "new01110262 = {'id': '01110262', 'label': ['KEINE', 'Flüchtlinge', 'Afrikaner:innen', 'Nationalität', 'Anderes Merkmal']}\n",
    "new03113327 = {'id': '03113327', 'label': ['Angriff der Menschenwürde', 'VVH-ALLG', 'POC', 'ethnische Herkunft / \"Rasse\"', 'Kinder', 'Die Grünen', 'Politische Einstellung', 'Anderes Merkmal'] }\n",
    "new01114326 = {'id': '01114326', 'label': ['Muslim:e/innen', 'Religion / Weltanschauung', 'Islamist:innen', 'Aufstachelung zu Hass', 'VVH-ALLG', 'Politische Einstellung']}\n",
    "new01111028 = {'id': '01111028', 'label': ['KEINE', 'Araber:in', 'ethnische Herkunft / \"Rasse\"']}\n",
    "new03113648 = {'id': '03113648', 'label': ['KEINE', 'Politische Einstellung', 'Nazis']}\n",
    "new01112254 = {'id': '01112254', 'label': ['KEINE', 'Pol:innen', 'In Deutschland lebende Ausländer:innen', 'Nationalität']}\n",
    "new02110710 = {'id': '02110710', 'label': ['KEINE', 'Araber:in', 'In Deutschland lebende Ausländer:innen', 'ethnische Herkunft / \"Rasse\"', 'POC', 'Afrikaner:innen', 'Nationalität']}\n",
    "new04111621 = {'id': '04111621', 'label': ['KEINE']}\n",
    "new03112728 = {'id': '03112728', 'label': ['KEINE']}\n",
    "\n",
    "# Entspricht damit nicht mehr der ursprünglichen Logik; Entscheidung: Palästinenser:innen eher Nationalität als Polit. Einstellung\n",
    "# >> alle entsprechenden Einträge umschreiben\n",
    "new02113786 = {'id': '02113786', 'label': ['KEINE', 'Palästinenser:innen', 'Nationalität']}\n",
    "new01113048 = {'id': '01113048', 'label': ['Palästinenser:innen', 'Nationalität', 'VVH-ALLG', 'Aufstachelung zu Hass'], 'tag1': 'NEG', 'tag2': 'HATE'}\n",
    "new01110156 = {'id': '01110156', 'label': ['Palästinenser:innen', 'Nationalität', 'VVH-ALLG', 'Aufstachelung zu Hass'], 'tag1': 'NEG', 'tag2': 'HATE'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrekturen für die Testdaten\n",
    "\n",
    "new01222281 = {'id': '01222281', 'label': ['Die Grünen', 'Türkischstämmige Deutsche','Nationalität', 'Politische Einstellung', 'KEINE']}\n",
    "new02220290 = {'id': '02220290', 'label': ['KEINE', 'die SPD', 'Politische Einstellung']}\n",
    "new01221146  = {'id': '01221146', 'label': ['KEINE', 'die SPD', 'Politische Einstellung']}\n",
    "new01220517 = {'id': '01220517', 'label': ['KEINE', 'In Deutschland lebende Ausländer:innen', 'Pol:innen', 'Migrant:innen', 'Nationalität', 'Anderes Merkmal']}\n",
    "new02221882 = {'id': '02221882', 'label': ['KEINE', 'Zionist:innen', 'Palästinenser:innen', 'Politische Einstellung', 'Nationalität']}\n",
    "new01223120 = {'id': '01223120', 'label': ['KEINE']}\n",
    "new01221025 = {'id': '01221025', 'label': ['Verharmlosen', 'VVH-NS']}\n",
    "new02222036 = {'id': '02222036', 'label': ['KEINE', 'Palästinenser:innen', 'Nationalität']}\n",
    "new01220250 = {'id': '01220250', 'label': ['KEINE', 'Palästinenser:innen', 'Nationalität']}\n",
    "new02221762 = {'id': '02221762', 'label': ['KEINE', 'AfD', 'Politische Einstellung', 'Islamist:innen', 'Araber:in', 'In Deutschland lebende Ausländer:innen', 'Nationalität', 'ethnische Herkunft / \"Rasse\"']}\n",
    "new01223162 = {'id': '01223162', 'label': ['KEINE', 'Islamist:innen', 'Politische Einstellung']}\n",
    "new02221146 = {'id': '02221146', 'label': ['Nazis', 'Aufforderung zu Gewalt- oder Willkürmaßnahmen', 'VVH-ALLG', 'Politische Einstellung']}\n",
    "new01220249 = {'id': '01220249', 'label': ['KEINE', 'In Deutschland lebende Ausländer:innen', 'Nationalität']}\n",
    "new02221991 = {'id': '02221991', 'label': ['KEINE', 'Palästinenser:innen', 'Zionist:innen', 'Politische Einstellung', 'Nationalität']}\n",
    "new02220270 = {'id': '02220270', 'label': ['KEINE', 'Araber:in', 'Afrikaner:innen', 'In Deutschland lebende Ausländer:innen', 'Nationalität', 'Religion / Weltanschauung', 'Muslim:e/innen', 'ethnische Herkunft / \"Rasse\"']}\n",
    "new02220311 = {'id': '02220311', 'label': ['KEINE', 'Araber:in', 'In Deutschland lebende Ausländer:innen', 'Afrikaner:innen', 'Muslim:e/innen', 'Religion / Weltanschauung', 'Nationalität', 'ethnische Herkunft / \"Rasse\"']}\n",
    "new01222167 = {'id': '01222167', 'label': ['KEINE', 'In Deutschland lebende Ausländer:innen', 'Islamist:innen', 'Die Grünen', 'Politische Einstellung', 'Asylbewerber:innen', 'Anderes Merkmal', 'Nationalität']}\n",
    "new01222700 = {'id': '01222700', 'label': ['KEINE', 'Anderes Merkmal', 'Sich illegal in Deutschland aufhaltende Personen']}\n",
    "new01222612 = {'id': '01222612', 'label': ['KEINE', 'Palästinenser:innen', 'Nationalität']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erkannte Fehler: Trainings- und Testannotationsdateien umschreiben, inkl. der neuen IDs (je +1)\n",
    "# in neue Dateien\n",
    "\n",
    "with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\RefKorpHateSpeechDe_Train_HATE_annotiert.json\", mode=\"r\", encoding=\"utf-8\") as trainf:\n",
    "    train_anno = trainf.read()\n",
    "    train_annotations = json.loads(train_anno)\n",
    "\n",
    "korrekturen_train = [new01110262, new03113327, new01114326, new01111028, new03113648, new01112254, new02110710, new04111621, new03112728, new02113786, new01113048, new01110156]\n",
    "for i in train_annotations:\n",
    "    for j in korrekturen_train:\n",
    "        if i[\"id\"] == j[\"id\"]:\n",
    "            i[\"label\"] = j[\"label\"]\n",
    "    i[\"id\"] = i[\"id\"][:4] + f'{int(i[\"id\"][4:])+1:04d}'\n",
    "\n",
    "\n",
    "train_anno_k = json.dumps(train_annotations)\n",
    "\n",
    "with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\RefKorpHateSpeechDe_Train_HATE_anno_korrigiert.json\", mode=\"w\", encoding=\"utf-8\") as trainf_k:\n",
    "    trainf_k.write(train_anno_k)\n",
    "\n",
    "\n",
    "with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\RefKorpHateSpeechDe_Test_HATE_annotiert.json\", mode=\"r\", encoding=\"utf-8\") as testf:\n",
    "    test_anno = testf.read()\n",
    "    test_annotations = json.loads(test_anno)\n",
    "\n",
    "korrekturen_test = [new01222281, new02220290, new01221146, new01220517, new02221882, new01223120, new01221025, new02222036, new01220250,\n",
    "                    new02221762, new01223162, new02221146, new01220249, new02221991, new02220270, new02220311, new01222167, new01222700, new01222612]\n",
    "\n",
    "for i in test_annotations:\n",
    "    for j in korrekturen_test:\n",
    "        if i[\"id\"] == j[\"id\"]:\n",
    "            i[\"label\"] = j[\"label\"]\n",
    "    i[\"id\"] = i[\"id\"][:4] + f'{int(i[\"id\"][4:])+1:04d}'\n",
    "\n",
    "test_anno_k = json.dumps(test_annotations)\n",
    "\n",
    "with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\RefKorpHateSpeechDe_Test_HATE_anno_korrigiert.json\", mode=\"w\", encoding=\"utf-8\") as testf_k:\n",
    "    testf_k.write(test_anno_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Annotationen formatieren und speichern\n",
    "\n",
    "- in unterschiedlicher Detailgenauigkeit speichern:\n",
    "    - VVH Ja/Nein, VVH-Allg Ja/Nein, VVH-NS Ja/Nein\n",
    "    - Gruppe Ja/Nein, Welches Gruppenmerkmal/Keine Gruppe, Welche Gruppe genau/Keine Gruppe \n",
    "    - Handlung VVH-Allg Ja/Nein, Welche Handlung genau/Keine Handlung\n",
    "    - Handlung VVH-NS Ja/Nein, Welche Handlung genau/Keine Handlung\n",
    "\n",
    "- gleichzeitig @user-Erwähnungen anonymisieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\RefKorpHateSpeechDe_Train_HATE_anno_korrigiert.json\", mode=\"r\", encoding=\"utf-8\") as in_hate_train:\n",
    "    hate_train = in_hate_train.read()\n",
    "    hate_train_anno = json.loads(hate_train)\n",
    "    for entry in hate_train_anno:\n",
    "        entry[\"data\"] = anonym_atuser(entry[\"data\"])\n",
    "\n",
    "\n",
    "with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\RefKorpHateSpeechDe_Test_HATE_anno_korrigiert.json\", mode=\"r\", encoding=\"utf-8\") as in_hate_test:\n",
    "    hate_test = in_hate_test.read()\n",
    "    hate_test_anno = json.loads(hate_test)\n",
    "    for entry in hate_test_anno:\n",
    "        entry[\"data\"] = anonym_atuser(entry[\"data\"])\n",
    "\n",
    "# Beispiel-Eintrag: {\"id\": \"01222380\", \"data\": \"den #Zentralrat der #Muslime sollte man komplett rausschmei\\u00dfen, er hat hier nichts zu suchen @aktuelleStunde #WDR\", \"label\": [\"KEINE\"], \"tag1\": \"NEG\", \"tag2\": \"HATE\"}\n",
    "\n",
    "# Verallgemeinerte Annotation\n",
    "\n",
    "# 1. VVH Ja/Nein:\n",
    "def transform_anno_vvh(corp):\n",
    "    new_anno = []\n",
    "    for entry in corp:\n",
    "        if \"KEINE\" in entry[\"label\"]:\n",
    "            entry[\"label\"] = \"KEINE\"\n",
    "        else:\n",
    "            entry[\"label\"] = \"VVH\"\n",
    "        new_anno.append(entry)\n",
    "    return new_anno\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Train_HATE_VVH.txt\", mode=\"w\", encoding=\"utf-8\") as out_vvh_train:\n",
    "#    for i in transform_anno_vvh(hate_train_anno):\n",
    "#        if i[\"id\"] not in schwarzeListe:\n",
    "#            out_vvh_train.write(\"\\t\".join((i[\"id\"], i[\"data\"], i[\"label\"]))+\"\\n\")\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Test_HATE_VVH.txt\", mode=\"w\", encoding=\"utf-8\") as out_vvh_test:\n",
    "#    for i in transform_anno_vvh(hate_test_anno):\n",
    "#        if i[\"id\"] not in schwarzeListe:\n",
    "#            out_vvh_test.write(\"\\t\".join((i[\"id\"], i[\"data\"], i[\"label\"]))+\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# 2.1   Gruppe Ja/Nein\n",
    "def transform_anno_gruppe(corp):\n",
    "    gruppe = {\"Nationalität\", 'ethnische Herkunft / \"Rasse\"', \"Religion / Weltanschauung\",\n",
    "                    \"Politische Einstellung\", \"Geschlecht\", \"Anderes Merkmal\"}\n",
    "    new_anno = []\n",
    "    for entry in corp:\n",
    "        if gruppe & set(entry[\"label\"]) != set():\n",
    "            entry[\"label\"] = \"Gruppe\"\n",
    "        else:\n",
    "            entry[\"label\"] = \"KeineGruppe\"\n",
    "        new_anno.append(entry)\n",
    "    return new_anno\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Train_HATE_Gruppe.txt\", mode=\"w\", encoding=\"utf-8\") as out_gr_train:\n",
    "#    for i in transform_anno_gruppe(hate_train_anno):\n",
    "#        if i[\"id\"] not in schwarzeListe:\n",
    "#            out_gr_train.write(\"\\t\".join((i[\"id\"], i[\"data\"], i[\"label\"]))+\"\\n\")\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Test_HATE_Gruppe.txt\", mode=\"w\", encoding=\"utf-8\") as out_gr_test:\n",
    "#    for i in transform_anno_gruppe(hate_test_anno):\n",
    "#        if i[\"id\"] not in schwarzeListe:\n",
    "#            out_gr_test.write(\"\\t\".join((i[\"id\"], i[\"data\"], i[\"label\"]))+\"\\n\")\n",
    "\n",
    "\n",
    "# 2.2   Welche Gruppe / Keine Gruppe\n",
    "def transform_anno_gruppe_det(corp):\n",
    "    gruppe = {\"Nationalität\", 'ethnische Herkunft / \"Rasse\"', \"Religion / Weltanschauung\",\n",
    "                    \"Politische Einstellung\", \"Geschlecht\", \"Anderes Merkmal\"}\n",
    "    new_anno = []\n",
    "    for entry in corp:\n",
    "        if gruppe & set(entry[\"label\"]) != set():\n",
    "            entry[\"label\"] = gruppe & set(entry[\"label\"])\n",
    "        else:\n",
    "            entry[\"label\"] = \"KeineGruppe\"\n",
    "        new_anno.append(entry)\n",
    "    return new_anno\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Train_HATE_GruppeDetail.txt\", mode=\"w\", encoding=\"utf-8\") as out_grd_train:\n",
    "#    for i in transform_anno_gruppe_det(hate_train_anno):\n",
    "#        out_grd_train.write()\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Test_HATE_GruppeDetail.txt\", mode=\"w\", encoding=\"utf-8\") as out_grd_test:\n",
    "#    for i in transform_anno_gruppe_det(hate_test_anno):\n",
    "#        out_grd_test.write()\n",
    "\n",
    "\n",
    "# 3.1   Handlung VVH-Allg Ja/Nein\n",
    "def transform_anno_handlung(corp):\n",
    "    handlung = {\"Aufstachelung zu Hass\", \"Aufforderung zu Gewalt- oder Willkürmaßnahmen\", \"Angriff der Menschenwürde\"}\n",
    "    new_anno = []\n",
    "    for entry in corp:\n",
    "        if handlung & set(entry[\"label\"]) != set():\n",
    "            entry[\"label\"] = \"Handlung\"\n",
    "        else:\n",
    "            entry[\"label\"] = \"KeineHandlung\"\n",
    "        new_anno.append(entry)\n",
    "    return new_anno\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Train_HATE_Handlung.txt\", mode=\"w\", encoding=\"utf-8\") as out_handl_train:\n",
    "#    for i in transform_anno_handlung(hate_train_anno):\n",
    "#        if i[\"id\"] not in schwarzeListe:\n",
    "#            out_handl_train.write(\"\\t\".join((i[\"id\"], i[\"data\"], i[\"label\"]))+\"\\n\")\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Test_HATE_Handlung.txt\", mode=\"w\", encoding=\"utf-8\") as out_handl_test:\n",
    "#    for i in transform_anno_handlung(hate_test_anno):\n",
    "#        if i[\"id\"] not in schwarzeListe:\n",
    "#           out_handl_test.write(\"\\t\".join((i[\"id\"], i[\"data\"], i[\"label\"]))+\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# 3.2   Welche Handlung VVH-Allg / Keine Handlung \n",
    "def transform_anno_handlung_det(corp):\n",
    "    handlung = {\"Aufstachelung zu Hass\", \"Aufforderung zu Gewalt- oder Willkürmaßnahmen\", \"Angriff der Menschenwürde\"}\n",
    "    new_anno = []\n",
    "    for entry in corp:\n",
    "        if handlung & entry[\"label\"] != set():\n",
    "            entry[\"label\"] = handlung & set(entry[\"label\"])\n",
    "        else:\n",
    "            entry[\"label\"] = \"KeineHandlung\"\n",
    "        new_anno.append(entry)\n",
    "    return new_anno\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Train_HATE_HandlungDetail.txt\", mode=\"w\", encoding=\"utf-8\") as out_handld_train:\n",
    "#    for i in transform_anno_handlung_det(hate_train_anno):\n",
    "#        out_handld_train.write()\n",
    "\n",
    "#with open(\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Test_HATE_HandlungDetail.txt\", mode=\"w\", encoding=\"utf-8\") as out_handld_test:\n",
    "#    for i in transform_anno_handlung_det(hate_test_anno):\n",
    "#        out_handld_test.write()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtGruppe = [\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Train_HATE_Gruppe.txt\",\n",
    "            \"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Test_HATE_Gruppe.txt\",\n",
    "            ]\n",
    "\n",
    "txtHandlung = [\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Train_HATE_Handlung.txt\",\n",
    "            \"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Test_HATE_Handlung.txt\"\n",
    "            ]\n",
    "\n",
    "txtPfade = [\"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Train_HATE_VVH.txt\",\n",
    "            \"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Test_HATE_VVH.txt\",\n",
    "            \"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Train_HATE_Gruppe.txt\",\n",
    "            \"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Test_HATE_Gruppe.txt\",\n",
    "            \"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Train_HATE_Handlung.txt\",\n",
    "            \"..\\Korpora\\Referenzdatensatz_HateSpeech_Deutsch\\HateSpeechDe_Test_HATE_Handlung.txt\",\n",
    "            ]\n",
    "\n",
    "import json\n",
    "\n",
    "# json-Format angleichen an das json-Format des großen Datensatzes\n",
    "\n",
    "\n",
    "for datei in txtHandlung:\n",
    "    with open(datei, mode=\"r\", encoding=\"utf8\") as in_txt:\n",
    "        inhalt = in_txt.readlines()\n",
    "        sep_inhalt = [eintrag.strip().split(\"\\t\") for eintrag in inhalt]\n",
    "        json_inhalt = json.dumps(sep_inhalt)\n",
    "        with open(datei.strip(\"txt\")+\"json\", mode=\"w\", encoding=\"utf-8\") as out_json:\n",
    "            out_json.write(json_inhalt)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfe21998ac49805528ba5c524b8c99ad95f34df1263c0d2d07976ea5fcbab9a8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
